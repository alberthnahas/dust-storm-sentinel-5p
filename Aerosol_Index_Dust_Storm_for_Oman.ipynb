{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Detecting Dust Storms using Sentinel-5P UV Aerosol Index\n",
        "\n",
        "\n",
        "## 1. Introduction\n",
        "\n",
        "Dust storms are significant meteorological events that can impact air quality, human health, transportation, and climate. Monitoring and detecting these events are crucial for early warning and impact assessment.\n",
        "\n",
        "Sentinel-5P, part of the Copernicus program, carries the TROPOMI instrument, which provides valuable atmospheric composition data. One of its key products is the **UV Aerosol Index (AER_AI_354_388)**. This index is sensitive to the presence of UV-absorbing aerosols in the atmospheric column, such as desert dust, biomass burning smoke, and volcanic ash. Positive AI values generally indicate the presence of these aerosols, with higher values suggesting a greater abundance or optical thickness.\n",
        "\n",
        "This Colab notebook demonstrates how to:\n",
        "* Connect to the `openEO` platform to access Sentinel-5P data from the Copernicus Data Space Ecosystem.\n",
        "* Retrieve and process daily mean UV Aerosol Index data for selected cities in Oman for a defined period (e.g., the year 2023).\n",
        "* Analyze the AI time series to identify potential dust events based on different AI thresholds.\n",
        "* Visualize the data through time series plots with event highlighting, histograms, and seasonal/monthly boxplots.\n",
        "\n",
        "## 2. Setup\n",
        "\n",
        "### 2.1 Install Necessary Libraries\n",
        "First, we need to install the required Python libraries. If you are running this in a new Colab environment, execute the following cell:"
      ],
      "metadata": {
        "id": "HMHRgws5908p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openeo xarray matplotlib pandas seaborn netcdf4 h5netcdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs3YwffI2P20",
        "outputId": "4be9a2c7-1196-4487-c171-03efa291e06c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openeo in /usr/local/lib/python3.11/dist-packages (0.41.0)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (2025.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Collecting netcdf4\n",
            "  Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: h5netcdf in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from openeo) (2.32.3)\n",
            "Requirement already satisfied: shapely>=1.6.4 in /usr/local/lib/python3.11/dist-packages (from openeo) (2.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from openeo) (2.0.2)\n",
            "Requirement already satisfied: pystac<1.12,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from openeo) (1.11.0)\n",
            "Requirement already satisfied: deprecated>=1.2.12 in /usr/local/lib/python3.11/dist-packages (from openeo) (1.2.18)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray) (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Collecting cftime (from netcdf4)\n",
            "  Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netcdf4) (2025.4.26)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from h5netcdf) (3.13.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.12->openeo) (1.17.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->openeo) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->openeo) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->openeo) (2.4.0)\n",
            "Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cftime, netcdf4\n",
            "Successfully installed cftime-1.6.4.post1 netcdf4-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.2 Authenticate with openEO (Copernicus Data Space Ecosystem)\n",
        "To access Sentinel-5P data via openEO, you need an account on the [Copernicus Data Space Ecosystem](https://dataspace.copernicus.eu/).\n",
        "When you run the ```openeo.connect(...).authenticate_oidc()``` command for the first time, it will typically guide you through an authentication process in your browser."
      ],
      "metadata": {
        "id": "FayaQrvy-Zgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. The Python Script for Dust Storm Detection\n",
        "The following Python script performs the complete workflow: data acquisition from Sentinel-5P, processing, and generation of analytical plots."
      ],
      "metadata": {
        "id": "G-Ui-BrG-ktw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td70h97017bE",
        "outputId": "9f809d23-b299-4b2d-ccb5-da2193ef2fe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to connect to openEO platform...\n",
            "Authenticated using refresh token.\n",
            "Successfully connected and authenticated with openEO.\n",
            "\n",
            "--- Configuration ---\n",
            "Target cities: ['Muscat', 'Salalah', 'Sohar', 'Nizwa', 'Sur', 'AlBuraimi']\n",
            "Temporal extent: 2023-01-01 to 2023-12-31\n",
            "Using product band: AER_AI_354_388\n",
            "Statistical analysis with AI thresholds: [0.75, 1.0, 1.5, 2.0, 2.5]\n",
            "Timeseries plot color highlights: Yellow (AI > 1.0 to <= 1.5), Orange (AI > 1.5 to <= 2.0), Red (AI > 2.0)\n",
            "\n",
            "--- Processing for city: Muscat (23.61, 58.54) ---\n",
            "Defining data loading for Muscat using band AER_AI_354_388...\n",
            "Data loading definition complete via openEO.\n",
            "Executing batch job for Muscat -> AerosolIndex354_388_2023_Muscat.nc ... (This may take several minutes)\n",
            "0:00:00 Job 'j-2505280347284ec0904500e8ae27d14a': send 'start'\n",
            "0:00:13 Job 'j-2505280347284ec0904500e8ae27d14a': created (progress 0%)\n",
            "0:00:18 Job 'j-2505280347284ec0904500e8ae27d14a': created (progress 0%)\n",
            "0:00:25 Job 'j-2505280347284ec0904500e8ae27d14a': created (progress 0%)\n",
            "0:00:33 Job 'j-2505280347284ec0904500e8ae27d14a': created (progress 0%)\n",
            "0:00:43 Job 'j-2505280347284ec0904500e8ae27d14a': running (progress N/A)\n",
            "0:00:55 Job 'j-2505280347284ec0904500e8ae27d14a': running (progress N/A)\n",
            "0:01:11 Job 'j-2505280347284ec0904500e8ae27d14a': running (progress N/A)\n",
            "0:01:30 Job 'j-2505280347284ec0904500e8ae27d14a': running (progress N/A)\n",
            "0:01:54 Job 'j-2505280347284ec0904500e8ae27d14a': running (progress N/A)\n",
            "0:02:25 Job 'j-2505280347284ec0904500e8ae27d14a': running (progress N/A)\n",
            "0:03:02 Job 'j-2505280347284ec0904500e8ae27d14a': running (progress N/A)\n",
            "0:03:49 Job 'j-2505280347284ec0904500e8ae27d14a': finished (progress 100%)\n",
            "Batch job for Muscat completed. Output NetCDF: AerosolIndex354_388_2023_Muscat.nc\n",
            "Attempting to load NetCDF data for Muscat from AerosolIndex354_388_2023_Muscat.nc ...\n",
            "Using time coordinate: t\n",
            "Using data variable: AER_AI_354_388\n",
            "Data processing complete for Muscat!\n",
            "Generating timeseries plot for Muscat...\n",
            "Saved timeseries plot: AerosolIndex354_388_timeseries_intensity_Muscat_2023.png\n",
            "Generating histogram for Muscat...\n",
            "Saved histogram: AerosolIndex354_388_histogram_Muscat_2023.png\n",
            "Generating seasonal boxplot for Muscat...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d6d93e604d44>:270: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x=\"season\", y=product_band, data=df_plot, palette=\"Set3\", order=season_order)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved seasonal boxplot: AerosolIndex354_388_seasonal_boxplot_Muscat_2023.png\n",
            "Generating monthly boxplot for Muscat...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d6d93e604d44>:294: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x=\"month_name\", y=product_band, data=df_plot, palette=\"coolwarm\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved monthly boxplot: AerosolIndex354_388_monthly_boxplot_Muscat_2023.png\n",
            "\n",
            "--- Processing for city: Salalah (17.0151, 54.0924) ---\n",
            "Defining data loading for Salalah using band AER_AI_354_388...\n",
            "Data loading definition complete via openEO.\n",
            "Executing batch job for Salalah -> AerosolIndex354_388_2023_Salalah.nc ... (This may take several minutes)\n",
            "0:00:00 Job 'j-2505280351274742931b0d823395c5d9': send 'start'\n",
            "0:00:12 Job 'j-2505280351274742931b0d823395c5d9': created (progress 0%)\n",
            "0:00:18 Job 'j-2505280351274742931b0d823395c5d9': created (progress 0%)\n",
            "0:00:24 Job 'j-2505280351274742931b0d823395c5d9': created (progress 0%)\n",
            "0:00:32 Job 'j-2505280351274742931b0d823395c5d9': created (progress 0%)\n",
            "0:00:42 Job 'j-2505280351274742931b0d823395c5d9': running (progress N/A)\n",
            "0:00:55 Job 'j-2505280351274742931b0d823395c5d9': running (progress N/A)\n",
            "0:01:10 Job 'j-2505280351274742931b0d823395c5d9': running (progress N/A)\n",
            "0:01:30 Job 'j-2505280351274742931b0d823395c5d9': running (progress N/A)\n",
            "0:01:54 Job 'j-2505280351274742931b0d823395c5d9': running (progress N/A)\n",
            "0:02:24 Job 'j-2505280351274742931b0d823395c5d9': running (progress N/A)\n",
            "0:03:01 Job 'j-2505280351274742931b0d823395c5d9': finished (progress 100%)\n",
            "Batch job for Salalah completed. Output NetCDF: AerosolIndex354_388_2023_Salalah.nc\n",
            "Attempting to load NetCDF data for Salalah from AerosolIndex354_388_2023_Salalah.nc ...\n",
            "Using time coordinate: t\n",
            "Using data variable: AER_AI_354_388\n",
            "Data processing complete for Salalah!\n",
            "Generating timeseries plot for Salalah...\n",
            "Saved timeseries plot: AerosolIndex354_388_timeseries_intensity_Salalah_2023.png\n",
            "Generating histogram for Salalah...\n",
            "Saved histogram: AerosolIndex354_388_histogram_Salalah_2023.png\n",
            "Generating seasonal boxplot for Salalah...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d6d93e604d44>:270: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x=\"season\", y=product_band, data=df_plot, palette=\"Set3\", order=season_order)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved seasonal boxplot: AerosolIndex354_388_seasonal_boxplot_Salalah_2023.png\n",
            "Generating monthly boxplot for Salalah...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d6d93e604d44>:294: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x=\"month_name\", y=product_band, data=df_plot, palette=\"coolwarm\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved monthly boxplot: AerosolIndex354_388_monthly_boxplot_Salalah_2023.png\n",
            "\n",
            "--- Processing for city: Sohar (24.3459, 56.7071) ---\n",
            "Defining data loading for Sohar using band AER_AI_354_388...\n",
            "Data loading definition complete via openEO.\n",
            "Executing batch job for Sohar -> AerosolIndex354_388_2023_Sohar.nc ... (This may take several minutes)\n",
            "0:00:00 Job 'j-2505280354384c8b9fb5a180650d7418': send 'start'\n",
            "0:00:13 Job 'j-2505280354384c8b9fb5a180650d7418': created (progress 0%)\n",
            "0:00:18 Job 'j-2505280354384c8b9fb5a180650d7418': created (progress 0%)\n",
            "0:00:24 Job 'j-2505280354384c8b9fb5a180650d7418': created (progress 0%)\n",
            "0:00:32 Job 'j-2505280354384c8b9fb5a180650d7418': running (progress N/A)\n",
            "0:00:42 Job 'j-2505280354384c8b9fb5a180650d7418': running (progress N/A)\n",
            "0:00:55 Job 'j-2505280354384c8b9fb5a180650d7418': running (progress N/A)\n",
            "0:01:10 Job 'j-2505280354384c8b9fb5a180650d7418': running (progress N/A)\n",
            "0:01:30 Job 'j-2505280354384c8b9fb5a180650d7418': running (progress N/A)\n",
            "0:01:54 Job 'j-2505280354384c8b9fb5a180650d7418': running (progress N/A)\n",
            "0:02:24 Job 'j-2505280354384c8b9fb5a180650d7418': running (progress N/A)\n",
            "0:03:01 Job 'j-2505280354384c8b9fb5a180650d7418': running (progress N/A)\n",
            "0:03:48 Job 'j-2505280354384c8b9fb5a180650d7418': finished (progress 100%)\n",
            "Batch job for Sohar completed. Output NetCDF: AerosolIndex354_388_2023_Sohar.nc\n",
            "Attempting to load NetCDF data for Sohar from AerosolIndex354_388_2023_Sohar.nc ...\n",
            "Using time coordinate: t\n",
            "Using data variable: AER_AI_354_388\n",
            "Data processing complete for Sohar!\n",
            "Generating timeseries plot for Sohar...\n",
            "Saved timeseries plot: AerosolIndex354_388_timeseries_intensity_Sohar_2023.png\n",
            "Generating histogram for Sohar...\n",
            "Saved histogram: AerosolIndex354_388_histogram_Sohar_2023.png\n",
            "Generating seasonal boxplot for Sohar...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d6d93e604d44>:270: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x=\"season\", y=product_band, data=df_plot, palette=\"Set3\", order=season_order)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved seasonal boxplot: AerosolIndex354_388_seasonal_boxplot_Sohar_2023.png\n",
            "Generating monthly boxplot for Sohar...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d6d93e604d44>:294: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x=\"month_name\", y=product_band, data=df_plot, palette=\"coolwarm\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved monthly boxplot: AerosolIndex354_388_monthly_boxplot_Sohar_2023.png\n",
            "\n",
            "--- Processing for city: Nizwa (22.9333, 57.5301) ---\n",
            "Defining data loading for Nizwa using band AER_AI_354_388...\n",
            "Data loading definition complete via openEO.\n",
            "Executing batch job for Nizwa -> AerosolIndex354_388_2023_Nizwa.nc ... (This may take several minutes)\n",
            "0:00:00 Job 'j-2505280358354cf29e79eaa4963ec18f': send 'start'\n",
            "0:00:13 Job 'j-2505280358354cf29e79eaa4963ec18f': created (progress 0%)\n",
            "0:00:18 Job 'j-2505280358354cf29e79eaa4963ec18f': created (progress 0%)\n",
            "0:00:25 Job 'j-2505280358354cf29e79eaa4963ec18f': created (progress 0%)\n",
            "0:00:33 Job 'j-2505280358354cf29e79eaa4963ec18f': running (progress N/A)\n",
            "0:00:43 Job 'j-2505280358354cf29e79eaa4963ec18f': running (progress N/A)\n",
            "0:00:55 Job 'j-2505280358354cf29e79eaa4963ec18f': running (progress N/A)\n",
            "0:01:11 Job 'j-2505280358354cf29e79eaa4963ec18f': running (progress N/A)\n",
            "0:01:31 Job 'j-2505280358354cf29e79eaa4963ec18f': running (progress N/A)\n",
            "0:01:55 Job 'j-2505280358354cf29e79eaa4963ec18f': running (progress N/A)\n",
            "0:02:25 Job 'j-2505280358354cf29e79eaa4963ec18f': running (progress N/A)\n",
            "0:03:03 Job 'j-2505280358354cf29e79eaa4963ec18f': finished (progress 100%)\n",
            "Batch job for Nizwa completed. Output NetCDF: AerosolIndex354_388_2023_Nizwa.nc\n",
            "Attempting to load NetCDF data for Nizwa from AerosolIndex354_388_2023_Nizwa.nc ...\n",
            "Using time coordinate: t\n",
            "Using data variable: AER_AI_354_388\n",
            "Data processing complete for Nizwa!\n",
            "Generating timeseries plot for Nizwa...\n",
            "Saved timeseries plot: AerosolIndex354_388_timeseries_intensity_Nizwa_2023.png\n",
            "Generating histogram for Nizwa...\n",
            "Saved histogram: AerosolIndex354_388_histogram_Nizwa_2023.png\n",
            "Generating seasonal boxplot for Nizwa...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d6d93e604d44>:270: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x=\"season\", y=product_band, data=df_plot, palette=\"Set3\", order=season_order)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved seasonal boxplot: AerosolIndex354_388_seasonal_boxplot_Nizwa_2023.png\n",
            "Generating monthly boxplot for Nizwa...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d6d93e604d44>:294: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x=\"month_name\", y=product_band, data=df_plot, palette=\"coolwarm\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved monthly boxplot: AerosolIndex354_388_monthly_boxplot_Nizwa_2023.png\n",
            "\n",
            "--- Processing for city: Sur (22.5667, 59.5289) ---\n",
            "Defining data loading for Sur using band AER_AI_354_388...\n",
            "Data loading definition complete via openEO.\n",
            "Executing batch job for Sur -> AerosolIndex354_388_2023_Sur.nc ... (This may take several minutes)\n",
            "0:00:00 Job 'j-2505280401484e82bf4cf8c959939db7': send 'start'\n",
            "0:00:12 Job 'j-2505280401484e82bf4cf8c959939db7': created (progress 0%)\n",
            "0:00:17 Job 'j-2505280401484e82bf4cf8c959939db7': running (progress N/A)\n",
            "0:00:24 Job 'j-2505280401484e82bf4cf8c959939db7': running (progress N/A)\n",
            "0:00:32 Job 'j-2505280401484e82bf4cf8c959939db7': running (progress N/A)\n",
            "0:00:42 Job 'j-2505280401484e82bf4cf8c959939db7': running (progress N/A)\n",
            "0:00:55 Job 'j-2505280401484e82bf4cf8c959939db7': running (progress N/A)\n",
            "0:01:10 Job 'j-2505280401484e82bf4cf8c959939db7': running (progress N/A)\n",
            "0:01:30 Job 'j-2505280401484e82bf4cf8c959939db7': running (progress N/A)\n"
          ]
        }
      ],
      "source": [
        "import openeo\n",
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Connect to your openEO backend\n",
        "# Ensure you are authenticated if running non-interactively\n",
        "try:\n",
        "    print(\"Attempting to connect to openEO platform...\")\n",
        "    connection = openeo.connect(\"openeo.dataspace.copernicus.eu\").authenticate_oidc()\n",
        "    print(\"Successfully connected and authenticated with openEO.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error connecting to openEO: {e}\")\n",
        "    print(\"Please ensure you can authenticate with openeo.dataspace.copernicus.eu\")\n",
        "    print(\"If running for the first time, follow the browser authentication steps.\")\n",
        "    exit()\n",
        "\n",
        "# -------------------------------\n",
        "# Section A. Configuration\n",
        "# -------------------------------\n",
        "print(\"\\n--- Configuration ---\")\n",
        "# Define AOIs for cities in Oman\n",
        "# Format: CityName: [longitude, latitude]\n",
        "cities_coordinates = {\n",
        "    \"Muscat\": [58.54, 23.61],\n",
        "    \"Salalah\": [54.0924, 17.0151],\n",
        "    \"Sohar\": [56.7071, 24.3459],\n",
        "    \"Nizwa\": [57.5301, 22.9333],\n",
        "    \"Sur\": [59.5289, 22.5667],\n",
        "    \"AlBuraimi\": [55.7890, 24.2441]\n",
        "}\n",
        "print(f\"Target cities: {list(cities_coordinates.keys())}\")\n",
        "\n",
        "# Define the temporal extent\n",
        "temporal_extent = [\"2023-01-01\", \"2023-12-31\"]\n",
        "year_str = temporal_extent[0][:4]\n",
        "print(f\"Temporal extent: {temporal_extent[0]} to {temporal_extent[1]}\")\n",
        "\n",
        "# Define Aerosol Index band and buffer for spatial extent\n",
        "product_band = \"AER_AI_354_388\" # UV Aerosol Index from Sentinel-5P\n",
        "product_name_for_file = \"AerosolIndex354_388\" # Used in filenames\n",
        "buffer_degrees = 0.5 # Buffer in degrees around the point for the spatial extent\n",
        "print(f\"Using product band: {product_band}\")\n",
        "\n",
        "# --- Multiple Dust Event Threshold Configuration ---\n",
        "# Define a list of thresholds for statistical reporting on plots\n",
        "dust_event_thresholds_list = [0.75, 1.0, 1.5, 2.0, 2.5]\n",
        "print(f\"Statistical analysis with AI thresholds: {dust_event_thresholds_list}\")\n",
        "\n",
        "# Define thresholds for colored scatter points on timeseries plot\n",
        "threshold_yellow_min = 1.0\n",
        "threshold_orange_min = 1.5\n",
        "threshold_red_min = 2.0\n",
        "print(f\"Timeseries plot color highlights: Yellow (AI > {threshold_yellow_min} to <= {threshold_orange_min}), Orange (AI > {threshold_orange_min} to <= {threshold_red_min}), Red (AI > {threshold_red_min})\")\n",
        "\n",
        "\n",
        "# Loop through each city for data acquisition, processing, and plotting\n",
        "for city_name, coords in cities_coordinates.items():\n",
        "    print(f\"\\n--- Processing for city: {city_name} ({coords[1]}, {coords[0]}) ---\")\n",
        "    lon, lat = coords\n",
        "\n",
        "    # -------------------------------\n",
        "    # Section B. Data Acquisition via openEO\n",
        "    # -------------------------------\n",
        "    print(f\"Defining data loading for {city_name} using band {product_band}...\")\n",
        "    try:\n",
        "        dataset = connection.load_collection(\n",
        "            \"SENTINEL_5P_L2\", # Sentinel-5P Level 2 data\n",
        "            temporal_extent=temporal_extent,\n",
        "            spatial_extent={\n",
        "                \"west\": lon - buffer_degrees, \"south\": lat - buffer_degrees,\n",
        "                \"east\": lon + buffer_degrees, \"north\": lat + buffer_degrees,\n",
        "                \"crs\": \"EPSG:4326\" # Coordinate Reference System\n",
        "            },\n",
        "            bands=[product_band], # Specify the Aerosol Index band\n",
        "        )\n",
        "        # Aggregate to daily mean values for the defined spatial extent\n",
        "        dataset_daily_spatial_mean = dataset.aggregate_temporal_period(reducer=\"mean\", period=\"day\")\n",
        "\n",
        "        # Further aggregate spatially to get a single time series for the point of interest (city location)\n",
        "        # This effectively takes the mean of the already daily-averaged data within the feature geometry.\n",
        "        feature_collection_geometry = {\n",
        "            \"type\": \"FeatureCollection\",\n",
        "            \"features\": [{\n",
        "                \"type\": \"Feature\",\n",
        "                \"geometry\": {\"type\": \"Point\", \"coordinates\": [lon, lat]},\n",
        "                \"properties\": {\"id\": city_name}\n",
        "            }]\n",
        "        }\n",
        "        processed_dataset = dataset_daily_spatial_mean.aggregate_spatial(\n",
        "            reducer=\"mean\", geometries=feature_collection_geometry\n",
        "        )\n",
        "        print(\"Data loading definition complete via openEO.\")\n",
        "\n",
        "        # Define output filename and job title for the batch job\n",
        "        output_filename = f\"{product_name_for_file}_{year_str}_{city_name}.nc\" # e.g., AerosolIndex354_388_2023_Muscat.nc\n",
        "        job_title = f\"{product_name_for_file} {year_str} - {city_name}\"\n",
        "\n",
        "        print(f\"Executing batch job for {city_name} -> {output_filename} ... (This may take several minutes)\")\n",
        "        # execute_batch submits the processing job to the openEO backend and downloads the result.\n",
        "        job = processed_dataset.execute_batch(title=job_title, outputfile=output_filename,\n",
        "                                             job_options={'driver-memory': '1g'}) # Example job option\n",
        "        print(f\"Batch job for {city_name} completed. Output NetCDF: {output_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR during openEO data acquisition or job execution for {city_name}: {e}\")\n",
        "        continue # Skip to the next city if an error occurs\n",
        "\n",
        "    # --------------------------------------------------------------------------------------\n",
        "    # Section C. Data Processing (once the NetCDF file is available locally)\n",
        "    # --------------------------------------------------------------------------------------\n",
        "    df_plot = None # Initialize DataFrame\n",
        "    print(f\"Attempting to load NetCDF data for {city_name} from {output_filename} ...\")\n",
        "    try:\n",
        "        # Load the downloaded NetCDF file using xarray\n",
        "        ds = xr.load_dataset(output_filename)\n",
        "\n",
        "        # Attempt to identify the time coordinate automatically\n",
        "        time_coord_name = 't' # Default assumption\n",
        "        if time_coord_name not in ds.coords:\n",
        "            potential_time_coords = [c for c in ds.coords if 'time' in c.lower() or ds[c].dtype == 'datetime64[ns]']\n",
        "            if potential_time_coords: time_coord_name = potential_time_coords[0]\n",
        "            elif list(ds.dims): time_coord_name = list(ds.dims)[0] # Fallback to first dimension\n",
        "            else: raise ValueError(\"No suitable time coordinate or dimension found in NetCDF.\")\n",
        "        print(f\"Using time coordinate: {time_coord_name}\")\n",
        "        ds[time_coord_name] = pd.to_datetime(ds[time_coord_name].values) # Ensure datetime format\n",
        "\n",
        "        # Attempt to identify the Aerosol Index data variable\n",
        "        data_variable_name_in_file = product_band # Ideal case\n",
        "        if data_variable_name_in_file not in ds.data_vars:\n",
        "            print(f\"Warning for {city_name}: Requested band '{data_variable_name_in_file}' not found as a direct data variable.\")\n",
        "            print(f\"Available data variables in NetCDF: {list(ds.data_vars.keys())}\")\n",
        "            found_alt = False\n",
        "            # Try common variations if the exact name isn't present\n",
        "            for var_name in ds.data_vars:\n",
        "                if \"aerosol_index\" in var_name.lower() or \"aer_ai\" in var_name.lower() or product_band.lower() in var_name.lower():\n",
        "                    data_variable_name_in_file = var_name\n",
        "                    print(f\"Using alternative data variable from file: '{data_variable_name_in_file}'\")\n",
        "                    found_alt = True; break\n",
        "            if not found_alt: # If still not found\n",
        "                if list(ds.data_vars): # Use the first available data variable as a last resort\n",
        "                    data_variable_name_in_file = list(ds.data_vars)[0]\n",
        "                    print(f\"Could not find a suitable aerosol index variable. Using first available data variable: '{data_variable_name_in_file}'\")\n",
        "                else:\n",
        "                    raise ValueError(\"No data variables found in the NetCDF file.\")\n",
        "        print(f\"Using data variable: {data_variable_name_in_file}\")\n",
        "\n",
        "        # Convert to pandas DataFrame for easier plotting with seaborn/matplotlib\n",
        "        df = ds[[data_variable_name_in_file]].to_dataframe().reset_index()\n",
        "        # Rename columns to standard names used in plotting sections\n",
        "        df.rename(columns={data_variable_name_in_file: product_band, time_coord_name: 't'}, inplace=True)\n",
        "\n",
        "        df_plot = df\n",
        "        print(f\"Data processing complete for {city_name}!\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERROR: File {output_filename} not found for {city_name}. Please ensure the openEO job completed and downloaded the file.\")\n",
        "        continue\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR loading or processing {output_filename} for {city_name}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Proceed to plotting only if data was successfully loaded and processed\n",
        "    if df_plot is None or df_plot.empty:\n",
        "        print(f\"No data available for visualization for {city_name}. Skipping plots.\")\n",
        "        continue\n",
        "    else:\n",
        "        # ----------------------------------------------------------\n",
        "        # Section D. Timeseries Plot (Enhanced with Multi-Color Dust Event Highlighting)\n",
        "        # ----------------------------------------------------------\n",
        "        print(f\"Generating timeseries plot for {city_name}...\")\n",
        "        df_plot[f\"{product_band}_7day_mean\"] = df_plot[product_band].rolling(window=7, center=True, min_periods=1).mean()\n",
        "\n",
        "        plt.figure(figsize=(17, 8))\n",
        "        # Plot all daily AI values as grey dots (background)\n",
        "        plt.plot(df_plot[\"t\"], df_plot[product_band], marker='o', markersize=4, linestyle='', color=\"lightgray\", label=f\"Daily {product_band}\", zorder=1)\n",
        "\n",
        "        # Define conditions for color highlighting\n",
        "        cond_yellow = (df_plot[product_band] > threshold_yellow_min) & (df_plot[product_band] <= threshold_orange_min)\n",
        "        cond_orange = (df_plot[product_band] > threshold_orange_min) & (df_plot[product_band] <= threshold_red_min)\n",
        "        cond_red = df_plot[product_band] > threshold_red_min\n",
        "\n",
        "        # Plot highlighted events\n",
        "        if cond_yellow.any():\n",
        "            plt.scatter(df_plot.loc[cond_yellow, \"t\"], df_plot.loc[cond_yellow, product_band],\n",
        "                        color='yellow', edgecolor='darkgoldenrod', marker='o', s=50,\n",
        "                        label=f\"AI ({threshold_yellow_min:.1f}-{threshold_orange_min:.1f})\", zorder=3, alpha=0.8)\n",
        "\n",
        "        if cond_orange.any():\n",
        "            plt.scatter(df_plot.loc[cond_orange, \"t\"], df_plot.loc[cond_orange, product_band],\n",
        "                        color='orange', edgecolor='saddlebrown', marker='o', s=60,\n",
        "                        label=f\"AI ({threshold_orange_min:.1f}-{threshold_red_min:.1f})\", zorder=4, alpha=0.8)\n",
        "\n",
        "        if cond_red.any():\n",
        "            plt.scatter(df_plot.loc[cond_red, \"t\"], df_plot.loc[cond_red, product_band],\n",
        "                        color='red', edgecolor='black', marker='o', s=70,\n",
        "                        label=f\"AI > {threshold_red_min:.1f}\", zorder=5, alpha=0.8)\n",
        "\n",
        "        plt.plot(df_plot[\"t\"], df_plot[f\"{product_band}_7day_mean\"], linestyle='--', color=\"blue\", label=\"7-day Rolling Mean\", zorder=2)\n",
        "\n",
        "        plt.title(f\"Daily {product_band} for {city_name} - {year_str} (Dust Intensity Highlighted)\", fontsize=16)\n",
        "        plt.ylabel(f\"{product_band} (Unitless)\")\n",
        "        plt.xlabel(\"Date\")\n",
        "\n",
        "        mean_val = df_plot[product_band].mean()\n",
        "        median_val = df_plot[product_band].median()\n",
        "        max_val = df_plot[product_band].max()\n",
        "        data_point_count = len(df_plot)\n",
        "\n",
        "        stats_text_lines = [\n",
        "            f\"Mean AI: {mean_val:.2f}\", f\"Median AI: {median_val:.2f}\",\n",
        "            f\"Max AI: {max_val:.2f}\", f\"Data Points: {data_point_count}\",\n",
        "            \"--- Event Days (Stat Thresholds) ---\"\n",
        "        ]\n",
        "        for thold in dust_event_thresholds_list: # Uses the separate list for stats\n",
        "            num_event_days_thold = (df_plot[product_band] > thold).sum()\n",
        "            stats_text_lines.append(f\"Days AI > {thold:.2f}: {num_event_days_thold}\")\n",
        "\n",
        "        stats_text = \"\\n\".join(stats_text_lines)\n",
        "        plt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes, verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round,pad=0.5', fc='white', alpha=0.85))\n",
        "\n",
        "        plt.grid(True)\n",
        "        plt.legend(loc='upper right')\n",
        "        plt.tight_layout()\n",
        "        plot_filename_timeseries = f'{product_name_for_file}_timeseries_intensity_{city_name}_{year_str}.png'\n",
        "        plt.savefig(plot_filename_timeseries, dpi=300)\n",
        "        print(f\"Saved timeseries plot: {plot_filename_timeseries}\")\n",
        "        # plt.show() # In Colab, plots usually show automatically or use plt.close()\n",
        "        plt.close() # Close the figure to free memory\n",
        "\n",
        "        # ----------------------------------------------------------\n",
        "        # Section E. Histogram of Aerosol Index Values\n",
        "        # ----------------------------------------------------------\n",
        "        print(f\"Generating histogram for {city_name}...\")\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.histplot(df_plot[product_band].dropna(), kde=True, bins=30) # dropna for robustness\n",
        "        plt.title(f\"Distribution of Daily {product_band} for {city_name} ({year_str})\", fontsize=16)\n",
        "        plt.xlabel(f\"{product_band} (Unitless)\")\n",
        "        plt.ylabel(\"Frequency\")\n",
        "        plt.axvline(mean_val, color='red', linestyle='dashed', linewidth=1, label=f'Mean: {mean_val:.2f}')\n",
        "        plt.axvline(median_val, color='green', linestyle='dashed', linewidth=1, label=f'Median: {median_val:.2f}')\n",
        "\n",
        "        hist_threshold_colors = plt.cm.viridis(np.linspace(0, 0.8, len(dust_event_thresholds_list)))\n",
        "        for i, thold in enumerate(dust_event_thresholds_list):\n",
        "            plt.axvline(thold, color=hist_threshold_colors[i], linestyle='dotted', linewidth=1.5, label=f'Stat Threshold: {thold:.2f}')\n",
        "\n",
        "        plt.legend()\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        plot_filename_hist = f'{product_name_for_file}_histogram_{city_name}_{year_str}.png'\n",
        "        plt.savefig(plot_filename_hist, dpi=300)\n",
        "        print(f\"Saved histogram: {plot_filename_hist}\")\n",
        "        plt.close()\n",
        "\n",
        "        # ----------------------------------------------------------\n",
        "        # Section F. Boxplot: Seasonal Analysis\n",
        "        # ----------------------------------------------------------\n",
        "        print(f\"Generating seasonal boxplot for {city_name}...\")\n",
        "        df_plot[\"month\"] = df_plot[\"t\"].dt.month\n",
        "        def assign_season(row_month): # Simple season assignment for Northern Hemisphere\n",
        "            if row_month in [12, 1, 2]: return 'Winter (DJF)'\n",
        "            elif row_month in [3, 4, 5]: return 'Spring (MAM)'\n",
        "            elif row_month in [6, 7, 8]: return 'Summer (JJA)'\n",
        "            else: return 'Fall (SON)'\n",
        "        df_plot[\"season\"] = df_plot[\"month\"].apply(assign_season)\n",
        "        season_order = [\"Winter (DJF)\", \"Spring (MAM)\", \"Summer (JJA)\", \"Fall (SON)\"]\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.boxplot(x=\"season\", y=product_band, data=df_plot, palette=\"Set3\", order=season_order)\n",
        "        plt.title(f\"Seasonal Distribution of {product_band} for {city_name} ({year_str})\", fontsize=16)\n",
        "        for thold_idx, thold in enumerate(dust_event_thresholds_list):\n",
        "            plt.axhline(y=thold, color=hist_threshold_colors[thold_idx], linestyle=':', linewidth=1.0, alpha=0.9)\n",
        "        plt.xlabel(\"Season\")\n",
        "        plt.ylabel(f\"{product_band} (Unitless)\")\n",
        "        plt.grid(axis=\"y\", linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        plot_filename_seasonal = f'{product_name_for_file}_seasonal_boxplot_{city_name}_{year_str}.png'\n",
        "        plt.savefig(plot_filename_seasonal, dpi=300)\n",
        "        print(f\"Saved seasonal boxplot: {plot_filename_seasonal}\")\n",
        "        plt.close()\n",
        "\n",
        "        # ----------------------------------------------------------\n",
        "        # Section G. Boxplot: Monthly Analysis\n",
        "        # ----------------------------------------------------------\n",
        "        print(f\"Generating monthly boxplot for {city_name}...\")\n",
        "        month_names_map = {\n",
        "            1: \"Jan\", 2: \"Feb\", 3: \"Mar\", 4: \"Apr\", 5: \"May\", 6: \"Jun\",\n",
        "            7: \"Jul\", 8: \"Aug\", 9: \"Sep\", 10: \"Oct\", 11: \"Nov\", 12: \"Dec\"\n",
        "        }\n",
        "        df_plot['month_name'] = pd.Categorical(df_plot['month'].map(month_names_map), categories=month_names_map.values(), ordered=True)\n",
        "\n",
        "        plt.figure(figsize=(12, 7))\n",
        "        sns.boxplot(x=\"month_name\", y=product_band, data=df_plot, palette=\"coolwarm\")\n",
        "        plt.title(f\"Monthly Distribution of {product_band} for {city_name} ({year_str})\", fontsize=16)\n",
        "        for thold_idx, thold in enumerate(dust_event_thresholds_list):\n",
        "            plt.axhline(y=thold, color=hist_threshold_colors[thold_idx], linestyle=':', linewidth=1.0, alpha=0.9)\n",
        "        plt.xlabel(\"Month\")\n",
        "        plt.ylabel(f\"{product_band} (Unitless)\")\n",
        "        plt.grid(axis=\"y\", linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        plot_filename_monthly = f'{product_name_for_file}_monthly_boxplot_{city_name}_{year_str}.png'\n",
        "        plt.savefig(plot_filename_monthly, dpi=300)\n",
        "        print(f\"Saved monthly boxplot: {plot_filename_monthly}\")\n",
        "        plt.close()\n",
        "\n",
        "print(\"\\n--- Script finished for all configured Omani cities. ---\")\n",
        "print(\"Output NetCDF files and PNG plots are saved in your Colab environment's current working directory.\")\n",
        "print(\"You can download them from the file browser panel on the left.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Understanding the Script\n",
        "\n",
        "The Python script is divided into several logical sections:\n",
        "\n",
        "### 4.1 Configuration (Section A)\n",
        "This is where you set the main parameters for your analysis:\n",
        "* **`cities_coordinates`**: A Python dictionary defining the cities you want to analyze (currently Omani cities) along with their longitude and latitude.\n",
        "    ```python\n",
        "    # Example:\n",
        "    # \"Muscat\": [58.54, 23.61],\n",
        "    ```\n",
        "* **`temporal_extent`**: A list specifying the start and end dates for data retrieval (e.g., `[\"YYYY-MM-DD\", \"YYYY-MM-DD\"]`).\n",
        "* **`product_band`**: Defines the specific Sentinel-5P UV Aerosol Index band to be used (`AER_AI_354_388`).\n",
        "* **`dust_event_thresholds_list`**: A list of Aerosol Index (AI) values. The script will report how many days exceed each of these thresholds. These are also plotted as reference lines on histograms and boxplots.\n",
        "* **`threshold_yellow_min`, `threshold_orange_min`, `threshold_red_min`**: These AI values define the ranges for color-coding events on the timeseries plot (yellow for AI > 1.0 to ≤ 1.5, orange for AI > 1.5 to ≤ 2.0, and red for AI > 2.0), providing a visual guide to event intensity.\n",
        "\n",
        "### 4.2 Data Acquisition (Section B)\n",
        "This section handles fetching the data:\n",
        "* It connects to the Copernicus Data Space Ecosystem using the `openeo` library.\n",
        "* A data cube (`dataset`) is defined for Sentinel-5P Level 2 data, filtered by your chosen time period, a geographical area around each city (defined by `buffer_degrees`), and the specific AI band.\n",
        "* **`aggregate_temporal_period(reducer=\"mean\", period=\"day\")`**: This openEO process computes the average AI value for each day within the retrieved data.\n",
        "* **`aggregate_spatial(reducer=\"mean\", geometries=...)`**: This further averages the daily AI values over the precise point geometry defined for each city, resulting in a single AI value per day for each city.\n",
        "* **`execute_batch(...)`**: This command sends the entire processing chain (data loading, filtering, and aggregation) as a job to the openEO backend. The backend performs the computation, and the script then downloads the resulting data as a NetCDF file. **Note:** This step can take several minutes for each city, depending on the data volume and backend load.\n",
        "\n",
        " 4.3 Data Processing (Section C)\n",
        "Once the data is downloaded for a city:\n",
        "* The NetCDF file (`.nc`) is loaded using the `xarray` library.\n",
        "* The script intelligently tries to identify the time coordinate and the AI data variable within the file.\n",
        "* The relevant data is then converted into a `pandas` DataFrame, which is a convenient format for time series analysis and plotting with `matplotlib` and `seaborn`.\n",
        "\n",
        "### 4.4 Plotting and Analysis (Sections D-G)\n",
        "For each city, the script generates and saves several analytical plots:\n",
        "* **Timeseries Plot (Intensity Highlighted)**:\n",
        "    * Displays daily AI values (grey dots) and a 7-day rolling mean (blue line).\n",
        "    * Highlights days with AI values in specific ranges using different colors:\n",
        "        * Yellow: `1.0 < AI <= 1.5`\n",
        "        * Orange: `1.5 < AI <= 2.0`\n",
        "        * Red: `AI > 2.0`\n",
        "    * Includes a text box with key summary statistics (mean, median, max AI) and the count of days exceeding various AI thresholds from `dust_event_thresholds_list`.\n",
        "* **Histogram**:\n",
        "    * Shows the frequency distribution of daily AI values.\n",
        "    * Includes vertical lines indicating the mean, median, and the AI thresholds from `dust_event_thresholds_list` for context.\n",
        "* **Seasonal Boxplot**:\n",
        "    * Illustrates the distribution of AI values for each meteorological season (Winter, Spring, Summer, Fall). This helps in identifying seasonal patterns in aerosol activity.\n",
        "* **Monthly Boxplot**:\n",
        "    * Similar to the seasonal plot, but breaks down the AI distribution by month, offering a more granular view of temporal patterns.\n",
        "\n",
        "\n",
        "## 5. Interpreting the Results\n",
        "\n",
        "* **Timeseries Plot**:\n",
        "    * **Grey dots**: Represent the raw daily AI values.\n",
        "    * **Blue dashed line**: The 7-day rolling mean helps visualize short-to-medium term trends by smoothing out daily noise.\n",
        "    * **Colored markers** (Yellow, Orange, Red): These provide an immediate visual classification of potential dust event intensity based on the AI value.\n",
        "        * **Yellow**: AI > 1.0 and ≤ 1.5 (suggests potential light to moderate aerosol events).\n",
        "        * **Orange**: AI > 1.5 and ≤ 2.0 (suggests moderate to significant aerosol events).\n",
        "        * **Red**: AI > 2.0 (suggests significant or strong aerosol events).\n",
        "    * The **statistics box** offers quantitative data: the overall average, median, and maximum AI, plus how many days exceeded specific AI thresholds. This is useful for comparing aerosol load across different periods or cities.\n",
        "\n",
        "* **Histogram**:\n",
        "    * This plot shows how often different AI values occurred. A distribution skewed towards higher values might suggest frequent or intense aerosol events.\n",
        "    * The **vertical lines** for mean, median, and defined thresholds help you see where the bulk of AI values lie in relation to these references.\n",
        "\n",
        "* **Boxplots (Seasonal and Monthly)**:\n",
        "    * Each box shows the **interquartile range (IQR)** (from 25th to 75th percentile), with a line inside marking the **median** (50th percentile). Whiskers typically extend to 1.5 times the IQR from the box edges, and points beyond that are often considered outliers.\n",
        "    * These plots are excellent for identifying which seasons or months consistently show higher AI values (indicating more frequent or intense dust/aerosol activity) or greater variability. The horizontal reference lines for the statistical thresholds add further context.\n",
        "\n",
        "\n",
        "## 6. Outputs\n",
        "\n",
        "For each city processed, the script will save the following files into your Google Colab environment's current working directory:\n",
        "\n",
        "* **A NetCDF file (`.nc`)**: Contains the daily AI time series data for the city (e.g., `AerosolIndex354_388_2023_Muscat.nc`).\n",
        "* **Four PNG image files** for the plots:\n",
        "    * `..._timeseries_intensity_CITY_YEAR.png`\n",
        "    * `..._histogram_CITY_YEAR.png`\n",
        "    * `..._seasonal_boxplot_CITY_YEAR.png`\n",
        "    * `..._monthly_boxplot_CITY_YEAR.png`\n",
        "\n",
        "You can download these files from the file browser panel on the left side of the Colab interface.\n",
        "\n",
        "\n",
        "## 7. Further Exploration and Considerations\n",
        "\n",
        "* **Validation**: Remember, the Aerosol Index is an *indicator*. For definitive dust storm confirmation and impact assessment, it's highly recommended to correlate high AI events with other data sources:\n",
        "    * Ground-based PM₂.₅ or PM₁₀ measurements from air quality monitoring stations.\n",
        "    * Visibility reports from meteorological stations.\n",
        "    * True-color satellite imagery (e.g., from MODIS, VIIRS, Sentinel-2, or Sentinel-3 SLSTR) to visually confirm the presence and extent of dust plumes.\n",
        "    * News reports or official advisories from meteorological agencies.\n",
        "* **Limitations of AI**:\n",
        "    * **Clouds**: Sentinel-5P AI retrievals are significantly affected by cloud cover. Data may be missing or less reliable on heavily clouded days.\n",
        "    * **Other Absorbing Aerosols**: While highly sensitive to dust, the UV AI can also be elevated by other UV-absorbing aerosols like smoke from biomass burning or volcanic ash. Regional knowledge and ancillary data are often needed for accurate attribution.\n",
        "    * **Altitude Information**: AI is a column-integrated product. It indicates the presence of aerosols in the atmospheric column but does not directly provide information on the altitude of the aerosol layer or, crucially, its surface concentration.\n",
        "* **Customization**:\n",
        "    * Modify the `cities_coordinates` dictionary to analyze different regions or add more cities.\n",
        "    * Adjust the `temporal_extent` to study different years, specific dust seasons, or known event periods.\n",
        "    * Experiment with the various AI `thresholds` in Section A to better align with regional characteristics or your specific definition of a dust event or different intensity levels.\n",
        "    * Explore other Sentinel-5P products (like NO₂, SO₂, CO) or different openEO collections if relevant to your research.\n",
        "\n",
        "\n",
        "## 8. Conclusion\n",
        "\n",
        "The Sentinel-5P UV Aerosol Index provides a powerful, freely accessible dataset for monitoring and detecting the presence of UV-absorbing aerosols, including desert dust. By leveraging `openEO` for efficient data access and Python for robust analysis and visualization (as demonstrated in this notebook), researchers, air quality forecasters, and public health officials can gain valuable insights into the frequency, intensity, and seasonality of dust events over specific regions. While AI is a strong indicator, always consider integrating complementary data sources for a comprehensive understanding of these complex atmospheric phenomena."
      ],
      "metadata": {
        "id": "LuJvD3Tt-01Z"
      }
    }
  ]
}